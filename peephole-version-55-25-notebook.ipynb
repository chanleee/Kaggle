{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T11:08:09.993703Z",
     "iopub.status.busy": "2023-12-10T11:08:09.993426Z",
     "iopub.status.idle": "2023-12-10T11:08:23.847098Z",
     "shell.execute_reply": "2023-12-10T11:08:23.846169Z",
     "shell.execute_reply.started": "2023-12-10T11:08:09.993674Z"
    },
    "papermill": {
     "duration": 11.004792,
     "end_time": "2023-11-12T19:57:40.468758",
     "exception": false,
     "start_time": "2023-11-12T19:57:29.463966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Input, Dense, LSTM, Dropout\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTMCell, RNN, Dense, Dropout, Input, Lambda, Bidirectional, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T11:08:23.849226Z",
     "iopub.status.busy": "2023-12-10T11:08:23.848583Z",
     "iopub.status.idle": "2023-12-10T11:08:23.854837Z",
     "shell.execute_reply": "2023-12-10T11:08:23.853884Z",
     "shell.execute_reply.started": "2023-12-10T11:08:23.849184Z"
    },
    "papermill": {
     "duration": 0.014557,
     "end_time": "2023-11-12T19:57:40.489695",
     "exception": false,
     "start_time": "2023-11-12T19:57:40.475138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "N_LAGS = 55\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 100000\n",
    "EPOCHS = 10000\n",
    "PATIENCE = 25\n",
    "DROPOUT = 0.5\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "SPLIT_DAY = 390\n",
    "\n",
    "N_STOCKS = 200\n",
    "N_DATES = 481\n",
    "N_SECONDS = 55\n",
    "\n",
    "RUN_TRAINING = False\n",
    "RUN_FOR_SUBMISSION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T11:08:23.858423Z",
     "iopub.status.busy": "2023-12-10T11:08:23.857363Z",
     "iopub.status.idle": "2023-12-10T11:08:23.893269Z",
     "shell.execute_reply": "2023-12-10T11:08:23.892165Z",
     "shell.execute_reply.started": "2023-12-10T11:08:23.858379Z"
    },
    "papermill": {
     "duration": 0.014007,
     "end_time": "2023-11-12T19:57:40.509748",
     "exception": false,
     "start_time": "2023-11-12T19:57:40.495741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "tf.keras.utils.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T11:08:23.895773Z",
     "iopub.status.busy": "2023-12-10T11:08:23.894725Z",
     "iopub.status.idle": "2023-12-10T11:08:42.841350Z",
     "shell.execute_reply": "2023-12-10T11:08:42.840247Z",
     "shell.execute_reply.started": "2023-12-10T11:08:23.895743Z"
    },
    "papermill": {
     "duration": 17.771743,
     "end_time": "2023-11-12T19:57:58.307019",
     "exception": false,
     "start_time": "2023-11-12T19:57:40.535276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/optiver-trading-at-the-close/train.csv\")\n",
    "df = df[[\"stock_id\", \"date_id\", \"seconds_in_bucket\", \"target\"]]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T11:08:42.842892Z",
     "iopub.status.busy": "2023-12-10T11:08:42.842592Z",
     "iopub.status.idle": "2023-12-10T11:08:42.980686Z",
     "shell.execute_reply": "2023-12-10T11:08:42.979757Z",
     "shell.execute_reply.started": "2023-12-10T11:08:42.842866Z"
    },
    "papermill": {
     "duration": 0.123841,
     "end_time": "2023-11-12T19:57:58.437878",
     "exception": false,
     "start_time": "2023-11-12T19:57:58.314037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=0):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "\n",
    "    print(f\"Memory usage of dataframe is {start_mem:.2f} MB\")\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Memory usage after optimization is: {end_mem:.2f} MB\")\n",
    "    decrease = 100 * (start_mem - end_mem) / start_mem\n",
    "    print(f\"Decreased by {decrease:.2f}%\")\n",
    "\n",
    "    return df\n",
    "\n",
    "df = reduce_mem_usage(df, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T11:08:42.982969Z",
     "iopub.status.busy": "2023-12-10T11:08:42.982504Z",
     "iopub.status.idle": "2023-12-10T11:08:44.409608Z",
     "shell.execute_reply": "2023-12-10T11:08:44.408658Z",
     "shell.execute_reply.started": "2023-12-10T11:08:42.982931Z"
    }
   },
   "outputs": [],
   "source": [
    "all_stock_ids = range(N_STOCKS)\n",
    "all_date_ids = range(N_DATES)\n",
    "all_seconds = [i * 10 for i in range(N_SECONDS)]\n",
    "\n",
    "multi_index = pd.MultiIndex.from_product([all_stock_ids, all_date_ids, all_seconds], \n",
    "                                         names=['stock_id', 'date_id', 'seconds_in_bucket'])\n",
    "\n",
    "df_full = df.set_index(['stock_id', 'date_id', 'seconds_in_bucket']).reindex(multi_index)\n",
    "df_full = df_full.fillna(0)\n",
    "df_full = df_full.reset_index()\n",
    "\n",
    "assert(df_full.shape[0] == N_STOCKS * N_DATES * N_SECONDS)\n",
    "\n",
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T11:08:44.411128Z",
     "iopub.status.busy": "2023-12-10T11:08:44.410807Z",
     "iopub.status.idle": "2023-12-10T11:08:44.418788Z",
     "shell.execute_reply": "2023-12-10T11:08:44.417695Z",
     "shell.execute_reply.started": "2023-12-10T11:08:44.411092Z"
    },
    "papermill": {
     "duration": 0.016468,
     "end_time": "2023-11-12T19:58:05.862862",
     "exception": false,
     "start_time": "2023-11-12T19:58:05.846394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def windowed_dataset(dataset, shuffle=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "    dataset = dataset.window(N_LAGS + 1, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(N_LAGS + 1))\n",
    "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "    if shuffle:\n",
    "      dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T11:08:44.422895Z",
     "iopub.status.busy": "2023-12-10T11:08:44.422414Z",
     "iopub.status.idle": "2023-12-10T11:08:48.250215Z",
     "shell.execute_reply": "2023-12-10T11:08:48.249225Z",
     "shell.execute_reply.started": "2023-12-10T11:08:44.422865Z"
    },
    "papermill": {
     "duration": 0.017117,
     "end_time": "2023-11-12T19:58:05.912858",
     "exception": false,
     "start_time": "2023-11-12T19:58:05.895741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_features(df):\n",
    "\n",
    "    all_stock_ids = range(N_STOCKS)\n",
    "    all_date_ids = df[\"date_id\"].unique()\n",
    "    all_seconds = [i * 10 for i in range(N_SECONDS)]\n",
    "    \n",
    "    multi_index = pd.MultiIndex.from_product([all_stock_ids, all_date_ids, all_seconds], \n",
    "                                             names=['stock_id', 'date_id', 'seconds_in_bucket'])\n",
    "    df_full = df.set_index(['stock_id', 'date_id', 'seconds_in_bucket']).reindex(multi_index)\n",
    "    df_full = df_full.fillna(0)\n",
    "    df_full = df_full.reset_index()\n",
    "    \n",
    "    df_pivoted = df_full.pivot_table(\n",
    "                values='target', \n",
    "                index=['date_id', 'seconds_in_bucket'], \n",
    "                columns='stock_id')\n",
    "\n",
    "    df_pivoted = df_pivoted.reset_index(drop=True)\n",
    "    df_pivoted.columns.name = None\n",
    "    \n",
    "    return df_pivoted\n",
    "\n",
    "build_features(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T11:08:48.251641Z",
     "iopub.status.busy": "2023-12-10T11:08:48.251355Z",
     "iopub.status.idle": "2023-12-10T11:08:48.256247Z",
     "shell.execute_reply": "2023-12-10T11:08:48.254984Z",
     "shell.execute_reply.started": "2023-12-10T11:08:48.251615Z"
    }
   },
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# from keras.initializers import GlorotUniform\n",
    "\n",
    "# warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "# warnings.filterwarnings('ignore', message=\"The initializer GlorotUniform is unseeded\")\n",
    "\n",
    "# initializer = GlorotUniform(seed=1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T11:08:48.258179Z",
     "iopub.status.busy": "2023-12-10T11:08:48.257738Z",
     "iopub.status.idle": "2023-12-10T11:08:48.304424Z",
     "shell.execute_reply": "2023-12-10T11:08:48.303388Z",
     "shell.execute_reply.started": "2023-12-10T11:08:48.258138Z"
    },
    "papermill": {
     "duration": 0.017448,
     "end_time": "2023-11-12T19:58:05.887923",
     "exception": false,
     "start_time": "2023-11-12T19:58:05.870475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(dropout=DROPOUT):\n",
    "#     model = Sequential()\n",
    "#     model.add(Input(shape=(N_LAGS, N_STOCKS)))\n",
    "#     model.add(Dropout(dropout))\n",
    "#     # LSTMCell에 peephole 연결 활성화\n",
    "#     lstm_cell = tfa.rnn.PeepholeLSTMCell(25)\n",
    "#     # LSTMCell을 RNN 레이어로 감싸기\n",
    "#     model.add(tf.keras.layers.RNN(lstm_cell, return_sequences=True))\n",
    "#     model.add(Dropout(dropout))\n",
    "#     # Lambda 레이어를 사용하여 시퀀스의 마지막 타임스텝을 선택\n",
    "#     model.add(Lambda(lambda x: x[:, -1, :]))\n",
    "#     model.add(Dense(N_STOCKS))\n",
    "#     model.compile(loss='mae', optimizer=Adam(learning_rate=LEARNING_RATE))\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(N_LAGS, N_STOCKS)))\n",
    "    model.add(Bidirectional(RNN(tfa.rnn.PeepholeLSTMCell(55,kernel_regularizer=l2(0.0001)), return_sequences=True))) # 25\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(dropout))\n",
    "    model.add(Bidirectional(RNN(tfa.rnn.PeepholeLSTMCell(25, kernel_regularizer=l2(0.0001))))) # 25\n",
    "    # model.add(Dropout(dropout))\n",
    "    model.add(Dense(N_STOCKS, kernel_regularizer=l2(0.0001)))\n",
    "    model.compile(loss='mae', optimizer=Adam(learning_rate=LEARNING_RATE))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T11:08:48.306051Z",
     "iopub.status.busy": "2023-12-10T11:08:48.305708Z",
     "iopub.status.idle": "2023-12-10T11:08:48.323566Z",
     "shell.execute_reply": "2023-12-10T11:08:48.322581Z",
     "shell.execute_reply.started": "2023-12-10T11:08:48.305994Z"
    },
    "papermill": {
     "duration": 791.746972,
     "end_time": "2023-11-12T20:11:17.748714",
     "exception": false,
     "start_time": "2023-11-12T19:58:06.001742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "if RUN_TRAINING:\n",
    "    \n",
    "    split = df_full['date_id'] > SPLIT_DAY\n",
    "    df_train = df_full[~split]\n",
    "    df_valid = df_full[split]\n",
    "    \n",
    "    df_train_features = build_features(df_train)\n",
    "    df_valid_features = build_features(df_valid)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    train_features = scaler.fit_transform(df_train_features)\n",
    "    valid_features = scaler.transform(df_valid_features)\n",
    " \n",
    "    train_dataset = windowed_dataset(train_features)\n",
    "    valid_dataset = windowed_dataset(valid_features, shuffle=False)\n",
    "\n",
    "    model = build_model()\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                      mode='min',\n",
    "                      patience=10,\n",
    "                      restore_best_weights=True,\n",
    "                      verbose=True)\n",
    "\n",
    "    history = model.fit(train_dataset,\n",
    "                        validation_data=valid_dataset,\n",
    "                        epochs=EPOCHS,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        callbacks=[early_stopping],\n",
    "                        verbose=True)\n",
    "\n",
    "    ## Evaluate ## \n",
    "    y_pred = model.predict(valid_dataset)\n",
    "\n",
    "    y_pred = scaler.inverse_transform(y_pred)\n",
    "    y_true = df_valid_features[N_LAGS:]\n",
    "    \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    print(f\"MAE score: {mae}\")\n",
    "\n",
    "    ## Plots ##\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model train vs validation loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T11:08:48.324991Z",
     "iopub.status.busy": "2023-12-10T11:08:48.324655Z",
     "iopub.status.idle": "2023-12-10T11:08:48.337618Z",
     "shell.execute_reply": "2023-12-10T11:08:48.336649Z",
     "shell.execute_reply.started": "2023-12-10T11:08:48.324963Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.save('peephole-version-55-25_ep17-5.73.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T11:08:48.339300Z",
     "iopub.status.busy": "2023-12-10T11:08:48.338948Z",
     "iopub.status.idle": "2023-12-10T11:08:56.654783Z",
     "shell.execute_reply": "2023-12-10T11:08:56.653726Z",
     "shell.execute_reply.started": "2023-12-10T11:08:48.339274Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "if RUN_FOR_SUBMISSION:\n",
    "    # model = load_model('/kaggle/input/model-version-chan-peephole/my_peephole_model.h5', custom_objects={'PeepholeLSTMCell': tfa.rnn.PeepholeLSTMCell})\n",
    "    # model 불러오는거는 데이터셋 이름에 맞게..!\n",
    "    model = load_model('/kaggle/input/peephole-version-55-25-ep17-5-73/peephole-version-55-25_ep17-5.73.h5', custom_objects={'PeepholeLSTMCell': tfa.rnn.PeepholeLSTMCell})\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    split = df_full['date_id'] > SPLIT_DAY\n",
    "    df_train = df_full[~split]\n",
    "    df_valid = df_full[split]\n",
    "\n",
    "    df_train_features = build_features(df_train)\n",
    "    df_valid_features = build_features(df_valid)\n",
    "\n",
    "    train_features = scaler.fit_transform(df_train_features)\n",
    "    valid_features = scaler.transform(df_valid_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T11:08:56.656878Z",
     "iopub.status.busy": "2023-12-10T11:08:56.656560Z",
     "iopub.status.idle": "2023-12-10T11:08:57.466672Z",
     "shell.execute_reply": "2023-12-10T11:08:57.465604Z",
     "shell.execute_reply.started": "2023-12-10T11:08:56.656851Z"
    },
    "papermill": {
     "duration": 11.347362,
     "end_time": "2023-11-12T20:11:34.686928",
     "exception": false,
     "start_time": "2023-11-12T20:11:23.339566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if RUN_FOR_SUBMISSION:\n",
    "    \n",
    "    import optiver2023\n",
    "    optiver2023.make_env.func_dict['__called__'] = False\n",
    "    env = optiver2023.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for i, (test, revealed_targets, sample_prediction) in enumerate(iter_test):\n",
    "        \n",
    "        if test.currently_scored.iloc[0]== False:\n",
    "            sample_prediction['target'] = 0\n",
    "            env.predict(sample_prediction)\n",
    "            counter += 1\n",
    "            continue        \n",
    "            \n",
    "        if test.seconds_in_bucket.unique()[0] == 0:\n",
    "\n",
    "            df_revealed_targets = revealed_targets[[\"stock_id\", \"revealed_date_id\", \"seconds_in_bucket\", \"revealed_target\"]]\n",
    "            df_revealed_targets = df_revealed_targets.rename(columns={'revealed_date_id': 'date_id', 'revealed_target': 'target'})\n",
    "\n",
    "            df_features = build_features(df_revealed_targets)\n",
    "\n",
    "            history_scaled = scaler.transform(df_features)\n",
    "\n",
    "        y_pred_scaled = model.predict(\n",
    "            history_scaled[-N_LAGS:][np.newaxis, :, :],\n",
    "            verbose=True)\n",
    "        \n",
    "        y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "        \n",
    "        sample_prediction['target'] = y_pred[0]\n",
    "        env.predict(sample_prediction)\n",
    "        counter += 1\n",
    "        \n",
    "        history_scaled = np.concatenate([history_scaled, y_pred_scaled])\n",
    "\n",
    "else:\n",
    "    print(\"Run for submission skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7056235,
     "sourceId": 57891,
     "sourceType": "competition"
    },
    {
     "datasetId": 4140705,
     "sourceId": 7167519,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30616,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 853.383666,
   "end_time": "2023-11-12T20:11:39.059795",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-12T19:57:25.676129",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
