# Kaggle
I’m sharing some of the code I used for a Kaggle competition here. Since the data is provided by Kaggle, I’ve refrained from uploading it due to potential permission issues. <br>

Our team did not participate continuously over the full two-week duration of this competition. Instead, we were more focused on another competition and only dedicated the final six hours to this one. However, this doesn't mean we took the competition lightly. We actively followed the discussion forums to stay updated on the latest trends and techniques being used.<br>

As the competition progressed, it became clear that the top-performing solutions were no longer improving single models, but were instead leveraging various ensemble techniques to maximize performance. In response, our team also concentrated on ensemble strategies.<br>

Ultimately, by increasing the weight of deep learning models in a weighted average ensemble of public solutions, we managed to secure second place out of 1,910 teams. This experience taught us that deep learning models can capture insights and patterns that tree-based models might miss—an insight we later applied to the Optiver: Trading at the Close competition.<br>
