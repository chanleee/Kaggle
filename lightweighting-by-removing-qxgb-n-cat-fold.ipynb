{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eccefc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:32:40.767240Z",
     "iopub.status.busy": "2025-01-13T06:32:40.766897Z",
     "iopub.status.idle": "2025-01-13T06:32:45.086579Z",
     "shell.execute_reply": "2025-01-13T06:32:45.085471Z"
    },
    "papermill": {
     "duration": 4.332502,
     "end_time": "2025-01-13T06:32:45.088776",
     "exception": false,
     "start_time": "2025-01-13T06:32:40.756274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install rtdl_num_embeddings -q --no-index --find-links=/kaggle/input/jane-street-import/rtdl_num_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b67416ee",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-13T06:32:45.107620Z",
     "iopub.status.busy": "2025-01-13T06:32:45.107379Z",
     "iopub.status.idle": "2025-01-13T06:32:56.290174Z",
     "shell.execute_reply": "2025-01-13T06:32:56.289297Z"
    },
    "papermill": {
     "duration": 11.193519,
     "end_time": "2025-01-13T06:32:56.291693",
     "exception": false,
     "start_time": "2025-01-13T06:32:45.098174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pickle\n",
    "import gc\n",
    "import warnings\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "# plotting and progress bar\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "# PyTorch Lightning\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, Timer\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# Gradient Boosting Models\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Miscellaneous\n",
    "import sys\n",
    "from tanm_reference import Model, make_parameter_groups\n",
    "import joblib\n",
    "import dill\n",
    "\n",
    "# Kaggle Evaluation\n",
    "import kaggle_evaluation.jane_street_inference_server\n",
    "\n",
    "# Warnings and Polars table settings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_columns = None\n",
    "pl.Config.set_tbl_rows(100)\n",
    "pl.Config.set_tbl_cols(400)\n",
    "pl.Config.set_fmt_table_cell_list_len(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e815f71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:32:56.310879Z",
     "iopub.status.busy": "2025-01-13T06:32:56.310332Z",
     "iopub.status.idle": "2025-01-13T06:32:56.317130Z",
     "shell.execute_reply": "2025-01-13T06:32:56.316369Z"
    },
    "papermill": {
     "duration": 0.017351,
     "end_time": "2025-01-13T06:32:56.318504",
     "exception": false,
     "start_time": "2025-01-13T06:32:56.301153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    seed = 42\n",
    "    target_col = \"responder_6\"\n",
    "    # feature_cols = [\"symbol_id\", \"time_id\"] + [f\"feature_{idx:02d}\" for idx in range(79)]+ [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "    feature_cols = [f\"feature_{idx:02d}\" for idx in range(79)]+ [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "    \n",
    "    model_paths = [\n",
    "        #\"/kaggle/input/js24-train-gbdt-model-with-lags-singlemodel/result.pkl\",\n",
    "        #\"/kaggle/input/js24-trained-gbdt-model/result.pkl\",\n",
    "        \"/kaggle/input/js-xs-nn-trained-model\",\n",
    "    ]\n",
    "    debug = False\n",
    "    lag_cols_rename = { f\"responder_{idx}_lag_1\" : f\"responder_{idx}\" for idx in range(9)}\n",
    "    lag_target_cols_name = [f\"responder_{idx}\" for idx in range(9)]\n",
    "    lag_cols_original = [\"date_id\", \"time_id\", \"symbol_id\"] + [f\"responder_{idx}\" for idx in range(9)]\n",
    "    model_path = \"/kaggle/input/janestreet-public-model/xgb_001.pkl\"\n",
    "    lag_ndays = 4\n",
    "    all_cols = [\"date_id\", \"symbol_id\", \"time_id\", \"weight\"] + [f\"feature_{idx:02d}\" for idx in range(79)]+ [f\"responder_{idx}_lag_1\" for idx in range(9)] + [target_col]\n",
    "    test_cols = [\"row_id\", \"date_id\", \"symbol_id\", \"time_id\"] + [f\"feature_{idx:02d}\" for idx in range(79)]+ [f\"responder_{idx}_lag_1\" for idx in range(9)] + [target_col]\n",
    "    feature_colss = [\"symbol_id\", \"time_id\"] + [f\"feature_{idx:02d}\" for idx in range(79)]+ [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "    #기억해두자 온라인 리트레인 feature cols를 feature colss로 바꿨다.\n",
    "    only_features = [\"row_id\", \"date_id\", \"symbol_id\", \"time_id\"] + [f\"feature_{idx:02d}\" for idx in range(79)]\n",
    "    only_lags = [\"row_id\", \"date_id\", \"symbol_id\", \"time_id\"] + [f\"responder_{idx}_lag_1\" for idx in range(9)] \n",
    "    data_paths = [\"/kaggle/input/lgbm-model-training/lgbm_model_0.json\",\"/kaggle/input/js24-preprocessing-create-lags/validation.parquet/\"]\n",
    "    retrain = True\n",
    "    EVAL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd487ab2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:32:56.335991Z",
     "iopub.status.busy": "2025-01-13T06:32:56.335760Z",
     "iopub.status.idle": "2025-01-13T06:32:56.340111Z",
     "shell.execute_reply": "2025-01-13T06:32:56.339346Z"
    },
    "papermill": {
     "duration": 0.014512,
     "end_time": "2025-01-13T06:32:56.341468",
     "exception": false,
     "start_time": "2025-01-13T06:32:56.326956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_agg_list(day, columns):\n",
    "    agg_mean_list = [pl.col(c).mean().name.suffix(f\"_mean_{day}d\") for c in columns]\n",
    "    agg_std_list = [pl.col(c).std().name.suffix(f\"_std_{day}d\") for c in columns]\n",
    "    agg_max_list = [pl.col(c).max().name.suffix(f\"_max_{day}d\") for c in columns]\n",
    "    agg_last_list = [pl.col(c).last().name.suffix(f\"_last_{day}d\") for c in columns]\n",
    "    agg_list = agg_mean_list + agg_std_list + agg_max_list + agg_last_list\n",
    "    return agg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4fb3b72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:32:56.358990Z",
     "iopub.status.busy": "2025-01-13T06:32:56.358767Z",
     "iopub.status.idle": "2025-01-13T06:32:56.370456Z",
     "shell.execute_reply": "2025-01-13T06:32:56.369674Z"
    },
    "papermill": {
     "duration": 0.021821,
     "end_time": "2025-01-13T06:32:56.371795",
     "exception": false,
     "start_time": "2025-01-13T06:32:56.349974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom R2 metric for validation\n",
    "def r2_val(y_true, y_pred, sample_weight):\n",
    "    r2 = 1 - np.average((y_pred - y_true) ** 2, weights=sample_weight) / (np.average((y_true) ** 2, weights=sample_weight) + 1e-38)\n",
    "    return r2\n",
    "\n",
    "\n",
    "class NN(LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dims, dropouts, lr, weight_decay):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        for i, hidden_dim in enumerate(hidden_dims):\n",
    "            layers.append(nn.BatchNorm1d(in_dim))\n",
    "            if i > 0:\n",
    "                layers.append(nn.SiLU())\n",
    "            if i < len(dropouts):\n",
    "                layers.append(nn.Dropout(dropouts[i]))\n",
    "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "            # layers.append(nn.ReLU())\n",
    "            in_dim = hidden_dim\n",
    "        layers.append(nn.Linear(in_dim, 1))  # 输出层\n",
    "        layers.append(nn.Tanh())\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 5 * self.model(x).squeeze(-1)  # 输出为一维张量\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        x, y, w = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y, reduction='none') * w  # 考虑样本权重\n",
    "        loss = loss.mean()\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, batch_size=x.size(0))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        x, y, w = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y, reduction='none') * w\n",
    "        loss = loss.mean()\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, batch_size=x.size(0))\n",
    "        self.validation_step_outputs.append((y_hat, y, w))\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"Calculate validation WRMSE at the end of the epoch.\"\"\"\n",
    "        y = torch.cat([x[1] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "        if self.trainer.sanity_checking:\n",
    "            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "        else:\n",
    "            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "            weights = torch.cat([x[2] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "            # r2_val\n",
    "            val_r_square = r2_val(y, prob, weights)\n",
    "            self.log(\"val_r_square\", val_r_square, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5,\n",
    "                                                               verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss',\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        if self.trainer.sanity_checking:\n",
    "            return\n",
    "        epoch = self.trainer.current_epoch\n",
    "        metrics = {k: v.item() if isinstance(v, torch.Tensor) else v for k, v in self.trainer.logged_metrics.items()}\n",
    "        formatted_metrics = {k: f\"{v:.5f}\" for k, v in metrics.items()}\n",
    "        print(f\"Epoch {epoch}: {formatted_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "772bd9b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:32:56.389347Z",
     "iopub.status.busy": "2025-01-13T06:32:56.389112Z",
     "iopub.status.idle": "2025-01-13T06:32:56.392606Z",
     "shell.execute_reply": "2025-01-13T06:32:56.391829Z"
    },
    "papermill": {
     "duration": 0.01335,
     "end_time": "2025-01-13T06:32:56.393745",
     "exception": false,
     "start_time": "2025-01-13T06:32:56.380395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_r2(y_true, y_pred, weights):\n",
    "    numerator = np.sum(weights * (y_true - y_pred) ** 2)\n",
    "    denominator = np.sum(weights * (y_true ** 2))\n",
    "    r2_score = 1 - (numerator / denominator)\n",
    "    return r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cce9ab5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:32:56.411037Z",
     "iopub.status.busy": "2025-01-13T06:32:56.410821Z",
     "iopub.status.idle": "2025-01-13T06:32:56.414462Z",
     "shell.execute_reply": "2025-01-13T06:32:56.413677Z"
    },
    "papermill": {
     "duration": 0.013638,
     "end_time": "2025-01-13T06:32:56.415622",
     "exception": false,
     "start_time": "2025-01-13T06:32:56.401984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGET = 'responder_6'\n",
    "FEAT_COLS_CAT = [f\"feature_{i:02d}\" for i in range(79)]\n",
    "FEAT_COLS_LGB = [f\"feature_{i:02d}\" for i in range(79)]+ ['responder_0_lag_1', 'responder_1_lag_1', 'responder_2_lag_1',\n",
    "       'responder_3_lag_1', 'responder_4_lag_1', 'responder_5_lag_1',\n",
    "       'responder_6_lag_1', 'responder_7_lag_1', 'responder_8_lag_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeacbcae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:32:56.432818Z",
     "iopub.status.busy": "2025-01-13T06:32:56.432621Z",
     "iopub.status.idle": "2025-01-13T06:33:19.314597Z",
     "shell.execute_reply": "2025-01-13T06:33:19.313581Z"
    },
    "papermill": {
     "duration": 22.892301,
     "end_time": "2025-01-13T06:33:19.316281",
     "exception": false,
     "start_time": "2025-01-13T06:32:56.423980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from the saved file.\n"
     ]
    }
   ],
   "source": [
    "# 이거는 catboost 일때\n",
    "\n",
    "model_path = '/kaggle/input/jsmodel-chan-lgbupdate'\n",
    "cat_file_name = 'catboost_models'\n",
    "lgb_file_name = 'lgb_models'\n",
    "\n",
    "lgb_models = joblib.load(f'{model_path}/{lgb_file_name}.pkl')\n",
    "catboost_models = joblib.load(f'{model_path}/{cat_file_name}.pkl')\n",
    "\n",
    "catboost_holdout_model = joblib.load(f'/kaggle/input/jsmodel-chan-catholdout/catboost_holdout_model.pkl')\n",
    "\n",
    "print(f\"Loaded model from the saved file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be87321f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:19.342354Z",
     "iopub.status.busy": "2025-01-13T06:33:19.342018Z",
     "iopub.status.idle": "2025-01-13T06:33:19.451163Z",
     "shell.execute_reply": "2025-01-13T06:33:19.450424Z"
    },
    "papermill": {
     "duration": 0.119877,
     "end_time": "2025-01-13T06:33:19.452530",
     "exception": false,
     "start_time": "2025-01-13T06:33:19.332653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n"
     ]
    }
   ],
   "source": [
    "with open( CONFIG.model_path, \"rb\") as fp:\n",
    "    result = pickle.load(fp)\n",
    "    \n",
    "model = result[\"model\"]\n",
    "features = result[\"features\"]\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6670f2ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:19.472945Z",
     "iopub.status.busy": "2025-01-13T06:33:19.472625Z",
     "iopub.status.idle": "2025-01-13T06:33:19.483207Z",
     "shell.execute_reply": "2025-01-13T06:33:19.482499Z"
    },
    "papermill": {
     "duration": 0.02114,
     "end_time": "2025-01-13T06:33:19.484549",
     "exception": false,
     "start_time": "2025-01-13T06:33:19.463409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_list = [f\"feature_{idx:02d}\" for idx in range(79) if idx != 61]\n",
    "\n",
    "target_col = \"responder_6\" \n",
    "\n",
    "feature_test = feature_list \\\n",
    "                + [f\"responder_{idx}_lag_1\" for idx in range(9)] \n",
    "\n",
    "feature_cat = [\"feature_09\", \"feature_10\", \"feature_11\"]\n",
    "feature_cont = [item for item in feature_test if item not in feature_cat]\n",
    "\n",
    "batch_size = 8192\n",
    "\n",
    "std_feature = [i for i in feature_list if i not in feature_cat] + [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "\n",
    "data_stats = joblib.load(\"/kaggle/input/my-own-js/data_stats.pkl\")\n",
    "means = data_stats['mean']\n",
    "stds = data_stats['std']\n",
    "\n",
    "def standardize(df, feature_cols, means, stds):\n",
    "    return df.with_columns([\n",
    "        ((pl.col(col) - means[col]) / stds[col]).alias(col) for col in feature_cols\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2baf7cb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:19.502324Z",
     "iopub.status.busy": "2025-01-13T06:33:19.502087Z",
     "iopub.status.idle": "2025-01-13T06:33:19.509389Z",
     "shell.execute_reply": "2025-01-13T06:33:19.508680Z"
    },
    "papermill": {
     "duration": 0.017667,
     "end_time": "2025-01-13T06:33:19.510724",
     "exception": false,
     "start_time": "2025-01-13T06:33:19.493057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "category_mappings = {'feature_09': {2: 0, 4: 1, 9: 2, 11: 3, 12: 4, 14: 5, 15: 6, 25: 7, 26: 8, 30: 9, 34: 10, 42: 11, 44: 12, 46: 13, 49: 14, 50: 15, 57: 16, 64: 17, 68: 18, 70: 19, 81: 20, 82: 21},\n",
    " 'feature_10': {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 10: 7, 12: 8},\n",
    " 'feature_11': {9: 0, 11: 1, 13: 2, 16: 3, 24: 4, 25: 5, 34: 6, 40: 7, 48: 8, 50: 9, 59: 10, 62: 11, 63: 12, 66: 13,\n",
    "  76: 14, 150: 15, 158: 16, 159: 17, 171: 18, 195: 19, 214: 20, 230: 21, 261: 22, 297: 23, 336: 24, 376: 25, 388: 26, 410: 27, 522: 28, 534: 29, 539: 30},\n",
    " 'symbol_id': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19,\n",
    "  20: 20, 21: 21, 22: 22, 23: 23, 24: 24, 25: 25, 26: 26, 27: 27, 28: 28, 29: 29, 30: 30, 31: 31, 32: 32, 33: 33, 34: 34, 35: 35, 36: 36, 37: 37, 38: 38},\n",
    " 'time_id' : {i : i for i in range(968)}}\n",
    "\n",
    "def encode_column(df, column, mapping):\n",
    "    max_value = max(mapping.values())  \n",
    "\n",
    "    def encode_category(category):\n",
    "        return mapping.get(category, max_value + 1)  \n",
    "    \n",
    "    return df.with_columns(\n",
    "        pl.col(column).map_elements(encode_category).alias(column)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e7db4ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:19.528812Z",
     "iopub.status.busy": "2025-01-13T06:33:19.528580Z",
     "iopub.status.idle": "2025-01-13T06:33:20.282723Z",
     "shell.execute_reply": "2025-01-13T06:33:20.282023Z"
    },
    "papermill": {
     "duration": 0.764815,
     "end_time": "2025-01-13T06:33:20.284166",
     "exception": false,
     "start_time": "2025-01-13T06:33:19.519351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class R2Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(R2Loss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        mse_loss = torch.sum((y_pred - y_true) ** 2)\n",
    "        var_y = torch.sum(y_true ** 2)\n",
    "        loss = mse_loss / (var_y + 1e-38)\n",
    "        return loss\n",
    "\n",
    "class TAB(LightningModule):\n",
    "    def __init__(self, n_cont_features, cat_cardinalities, n_classes, lr, weight_decay):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.k = 16\n",
    "        self.model = Model(\n",
    "                n_num_features=n_cont_features,\n",
    "                cat_cardinalities=cat_cardinalities,\n",
    "                n_classes=n_classes,\n",
    "                backbone={\n",
    "                    'type': 'MLP',\n",
    "                    'n_blocks': 3 ,\n",
    "                    'd_block': 512,\n",
    "                    'dropout': 0.25,\n",
    "                },\n",
    "                bins=None,\n",
    "                num_embeddings= None,\n",
    "                arch_type='tabm',\n",
    "                k=self.k,\n",
    "            )\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.loss_fn = R2Loss()\n",
    "        # self.loss_fn = weighted_mse_loss\n",
    "\n",
    "    def forward(self, x_cont, x_cat):\n",
    "        return self.model(x_cont, x_cat).squeeze(-1)\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        x_cont,x_cat, y, w , w_y= batch\n",
    "        x_cont = x_cont + torch.randn_like(x_cont) * 0.02\n",
    "        y_hat = self(x_cont, x_cat)\n",
    "        # loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k), w_y.repeat_interleave(self.k))\n",
    "        loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k))\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, batch_size=x_cont.size(0))\n",
    "        self.training_step_outputs.append((y_hat.mean(1), y, w))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        x_cont,x_cat, y, w, w_y = batch\n",
    "        x_cont = x_cont + torch.randn_like(x_cont) * 0.02\n",
    "        y_hat = self(x_cont, x_cat)\n",
    "        # loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k), w_y.repeat_interleave(self.k))\n",
    "        loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k))\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=x_cont.size(0))\n",
    "        self.validation_step_outputs.append((y_hat.mean(1), y, w))\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"Calculate validation WRMSE at the end of the epoch.\"\"\"\n",
    "        y = torch.cat([x[1] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "        if self.trainer.sanity_checking:\n",
    "            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "        else:\n",
    "            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "            weights = torch.cat([x[2] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "            # r2_val\n",
    "            val_r_square = r2_val(y, prob, weights)\n",
    "            self.log(\"val_r_square\", val_r_square, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(make_parameter_groups(self.model), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5,\n",
    "        #                                                        verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            # 'lr_scheduler': {\n",
    "            #     'scheduler': scheduler,\n",
    "            #     'monitor': 'val_r_square',\n",
    "            # }\n",
    "        }\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        if self.trainer.sanity_checking:\n",
    "            return\n",
    "\n",
    "        y = torch.cat([x[1] for x in self.training_step_outputs]).cpu().numpy()\n",
    "        prob = torch.cat([x[0] for x in self.training_step_outputs]).detach().cpu().numpy()\n",
    "        weights = torch.cat([x[2] for x in self.training_step_outputs]).cpu().numpy()\n",
    "        # r2_training\n",
    "        train_r_square = r2_val(y, prob, weights)\n",
    "        self.log(\"train_r_square\", train_r_square, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.training_step_outputs.clear()\n",
    "\n",
    "        epoch = self.trainer.current_epoch\n",
    "        metrics = {k: v.item() if isinstance(v, torch.Tensor) else v for k, v in self.trainer.logged_metrics.items()}\n",
    "        formatted_metrics = {k: f\"{v:.5f}\" for k, v in metrics.items()}\n",
    "        print(f\"Epoch {epoch}: {formatted_metrics}\")\n",
    "        \n",
    "class custom_args():\n",
    "    def __init__(self):\n",
    "        self.usegpu = True\n",
    "        self.gpuid = 0\n",
    "        self.seed = 42\n",
    "        self.model = 'nn'\n",
    "        self.use_wandb = False\n",
    "        self.project = 'js-tabm-with-lags'\n",
    "        self.dname = \"./input_df/\"\n",
    "        self.loader_workers = 10   \n",
    "        self.bs = 8192\n",
    "        self.lr = 1e-3\n",
    "        self.weight_decay = 8e-4\n",
    "        self.n_cont_features = 84\n",
    "        self.n_cat_features = 5\n",
    "        self.n_classes = None\n",
    "        self.cat_cardinalities = [23, 10, 32, 40, 969]\n",
    "        self.patience = 7\n",
    "        self.max_epochs = 10\n",
    "        self.N_fold = 5\n",
    "\n",
    "\n",
    "my_args = custom_args()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tab_model = TAB.load_from_checkpoint('/kaggle/input/my-own-js/tabm_epochepoch03.ckpt').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f000959",
   "metadata": {
    "papermill": {
     "duration": 0.00822,
     "end_time": "2025-01-13T06:33:20.301420",
     "exception": false,
     "start_time": "2025-01-13T06:33:20.293200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62f72034",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:20.319008Z",
     "iopub.status.busy": "2025-01-13T06:33:20.318781Z",
     "iopub.status.idle": "2025-01-13T06:33:20.751622Z",
     "shell.execute_reply": "2025-01-13T06:33:20.750732Z"
    },
    "papermill": {
     "duration": 0.443362,
     "end_time": "2025-01-13T06:33:20.753091",
     "exception": false,
     "start_time": "2025-01-13T06:33:20.309729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (model): Sequential(\n",
       "    (0): BatchNorm1d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.1, inplace=False)\n",
       "    (2): Linear(in_features=88, out_features=512, bias=True)\n",
       "    (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): SiLU()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): SiLU()\n",
       "    (9): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (10): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (11): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_folds = 5\n",
    "# 加载最佳模型\n",
    "nn_models = []\n",
    "for fold in range(N_folds):\n",
    "    checkpoint_path = f\"{CONFIG.model_paths[0]}/nn_{fold}.model\"\n",
    "    nn_model = NN.load_from_checkpoint(checkpoint_path)\n",
    "    nn_models.append(nn_model.to(\"cuda:0\"))\n",
    "nn_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cc38edc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:20.772632Z",
     "iopub.status.busy": "2025-01-13T06:33:20.772380Z",
     "iopub.status.idle": "2025-01-13T06:33:21.113643Z",
     "shell.execute_reply": "2025-01-13T06:33:21.112760Z"
    },
    "papermill": {
     "duration": 0.351974,
     "end_time": "2025-01-13T06:33:21.115014",
     "exception": false,
     "start_time": "2025-01-13T06:33:20.763040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date_id</th><th>time_id</th><th>symbol_id</th><th>responder_0</th><th>responder_1</th><th>responder_2</th><th>responder_3</th><th>responder_4</th><th>responder_5</th><th>responder_6</th><th>responder_7</th><th>responder_8</th></tr><tr><td>i16</td><td>i16</td><td>i16</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>-1</td><td>967</td><td>34</td><td>0.501321</td><td>0.905332</td><td>-0.819582</td><td>-0.564046</td><td>-0.223018</td><td>-0.283954</td><td>-0.045938</td><td>0.009797</td><td>-0.102538</td></tr><tr><td>-1</td><td>967</td><td>35</td><td>-1.113053</td><td>0.69719</td><td>-1.619031</td><td>-1.222743</td><td>-0.706082</td><td>-0.291133</td><td>0.167733</td><td>0.099704</td><td>0.32461</td></tr><tr><td>-1</td><td>967</td><td>36</td><td>-1.019353</td><td>-0.460962</td><td>-2.026678</td><td>-0.848606</td><td>-0.305448</td><td>-1.256913</td><td>-0.109359</td><td>-0.027474</td><td>-0.253956</td></tr><tr><td>-1</td><td>967</td><td>37</td><td>0.23585</td><td>0.556479</td><td>0.618944</td><td>-0.243765</td><td>-0.108361</td><td>-0.260777</td><td>-0.486923</td><td>-0.275566</td><td>-1.020708</td></tr><tr><td>-1</td><td>967</td><td>38</td><td>0.542563</td><td>0.513193</td><td>0.814393</td><td>0.032767</td><td>0.025435</td><td>0.311465</td><td>-0.044797</td><td>0.011133</td><td>-0.0793</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 12)\n",
       "┌────────┬────────┬────────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐\n",
       "│ date_i ┆ time_i ┆ symbol ┆ respo ┆ respo ┆ respo ┆ respo ┆ respo ┆ respo ┆ respo ┆ respo ┆ respo │\n",
       "│ d      ┆ d      ┆ _id    ┆ nder_ ┆ nder_ ┆ nder_ ┆ nder_ ┆ nder_ ┆ nder_ ┆ nder_ ┆ nder_ ┆ nder_ │\n",
       "│ ---    ┆ ---    ┆ ---    ┆ 0     ┆ 1     ┆ 2     ┆ 3     ┆ 4     ┆ 5     ┆ 6     ┆ 7     ┆ 8     │\n",
       "│ i16    ┆ i16    ┆ i16    ┆ ---   ┆ ---   ┆ ---   ┆ ---   ┆ ---   ┆ ---   ┆ ---   ┆ ---   ┆ ---   │\n",
       "│        ┆        ┆        ┆ f32   ┆ f32   ┆ f32   ┆ f32   ┆ f32   ┆ f32   ┆ f32   ┆ f32   ┆ f32   │\n",
       "╞════════╪════════╪════════╪═══════╪═══════╪═══════╪═══════╪═══════╪═══════╪═══════╪═══════╪═══════╡\n",
       "│ -1     ┆ 967    ┆ 34     ┆ 0.501 ┆ 0.905 ┆ -0.81 ┆ -0.56 ┆ -0.22 ┆ -0.28 ┆ -0.04 ┆ 0.009 ┆ -0.10 │\n",
       "│        ┆        ┆        ┆ 321   ┆ 332   ┆ 9582  ┆ 4046  ┆ 3018  ┆ 3954  ┆ 5938  ┆ 797   ┆ 2538  │\n",
       "│ -1     ┆ 967    ┆ 35     ┆ -1.11 ┆ 0.697 ┆ -1.61 ┆ -1.22 ┆ -0.70 ┆ -0.29 ┆ 0.167 ┆ 0.099 ┆ 0.324 │\n",
       "│        ┆        ┆        ┆ 3053  ┆ 19    ┆ 9031  ┆ 2743  ┆ 6082  ┆ 1133  ┆ 733   ┆ 704   ┆ 61    │\n",
       "│ -1     ┆ 967    ┆ 36     ┆ -1.01 ┆ -0.46 ┆ -2.02 ┆ -0.84 ┆ -0.30 ┆ -1.25 ┆ -0.10 ┆ -0.02 ┆ -0.25 │\n",
       "│        ┆        ┆        ┆ 9353  ┆ 0962  ┆ 6678  ┆ 8606  ┆ 5448  ┆ 6913  ┆ 9359  ┆ 7474  ┆ 3956  │\n",
       "│ -1     ┆ 967    ┆ 37     ┆ 0.235 ┆ 0.556 ┆ 0.618 ┆ -0.24 ┆ -0.10 ┆ -0.26 ┆ -0.48 ┆ -0.27 ┆ -1.02 │\n",
       "│        ┆        ┆        ┆ 85    ┆ 479   ┆ 944   ┆ 3765  ┆ 8361  ┆ 0777  ┆ 6923  ┆ 5566  ┆ 0708  │\n",
       "│ -1     ┆ 967    ┆ 38     ┆ 0.542 ┆ 0.513 ┆ 0.814 ┆ 0.032 ┆ 0.025 ┆ 0.311 ┆ -0.04 ┆ 0.011 ┆ -0.07 │\n",
       "│        ┆        ┆        ┆ 563   ┆ 193   ┆ 393   ┆ 767   ┆ 435   ┆ 465   ┆ 4797  ┆ 133   ┆ 93    │\n",
       "└────────┴────────┴────────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = pl.scan_parquet(\n",
    "    \"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet\"\n",
    ").select(['date_id','time_id','symbol_id'] + [f\"responder_{idx}\" for idx in range(9)]).filter(\n",
    "    (pl.col(\"date_id\")>=(1698 - CONFIG.lag_ndays))&(pl.col(\"date_id\")<1698)\n",
    ")\n",
    "\n",
    "# 这里将历史date_id变为从-N到-1, 假设test的date_id=0紧随train的date_id=1698,\n",
    "# 在第一个batch给出的lags应该是date_id=1698的responser(但date_id给的0),\n",
    "# 这样history中最后一个date_id=1697变为-1, 正好可以和推理时给的lags衔接上\n",
    "history = history.with_columns(\n",
    "    date_id = (pl.col(\"date_id\") - pl.lit(1698)).cast(pl.Int16)\n",
    ")\n",
    "history = history.collect()\n",
    "\n",
    "# 这里是为了统一特征的dtypes(polars在concat时如果dtype对不上会报错)\n",
    "history_column_types = {\n",
    "    'date_id': pl.Int16,\n",
    "    'time_id': pl.Int16,\n",
    "    'symbol_id': pl.Int16\n",
    "}\n",
    "feature_column_types = {}\n",
    "for f in [f\"feature_{idx:02d}\" for idx in range(79)]:\n",
    "    feature_column_types[f] = pl.Float32\n",
    "\n",
    "responder_column_types = {}\n",
    "for f in [f\"responder_{idx}\" for idx in range(9)]:\n",
    "    responder_column_types[f] = pl.Float32\n",
    "\n",
    "history = history.cast(history_column_types)\n",
    "history = history.cast(responder_column_types)\n",
    "history.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9dd21e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:21.134160Z",
     "iopub.status.busy": "2025-01-13T06:33:21.133926Z",
     "iopub.status.idle": "2025-01-13T06:33:21.141042Z",
     "shell.execute_reply": "2025-01-13T06:33:21.140253Z"
    },
    "papermill": {
     "duration": 0.017677,
     "end_time": "2025-01-13T06:33:21.142283",
     "exception": false,
     "start_time": "2025-01-13T06:33:21.124606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"/kaggle/input/jsridgev01011635/Ridge.dill\", \"rb\") as file_handle:\n",
    "    rdg = dill.load(file_handle)\n",
    "\n",
    "def predict_ridge(test, lags):\n",
    "    cols = [f'feature_{i:02}' for i in range(79)]\n",
    "    predictions = test.select(\n",
    "        'row_id',\n",
    "        pl.lit(0.0).alias('responder_6'),\n",
    "    )\n",
    "    test_preds = rdg.predict(test[cols].to_pandas().fillna(3).values)\n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "476d4b83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:21.160434Z",
     "iopub.status.busy": "2025-01-13T06:33:21.160144Z",
     "iopub.status.idle": "2025-01-13T06:33:21.268686Z",
     "shell.execute_reply": "2025-01-13T06:33:21.267961Z"
    },
    "papermill": {
     "duration": 0.119015,
     "end_time": "2025-01-13T06:33:21.269952",
     "exception": false,
     "start_time": "2025-01-13T06:33:21.150937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_feature_cols = [\"symbol_id\", \"time_id\"] + [f\"feature_{idx:02d}\" for idx in range(79)] + [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "\n",
    "xgb_model = None\n",
    "model_path = \"/kaggle/input/als-e-106-pp0-40-xgb-5fold/result0.pkl\"\n",
    "with open( model_path, \"rb\") as fp:\n",
    "    result = pickle.load(fp)\n",
    "    xgb_model = result[\"model\"] # モデルオブジェクトを指定\n",
    "    xgb_model.set_params(\n",
    "        early_stopping_rounds=50,\n",
    "        gamma=0.4,\n",
    "        tree_method=\"hist\",\n",
    "        max_depth=5,\n",
    "        eval_metric='rmse',\n",
    "        learning_rate=0.05\n",
    "    )\n",
    "\n",
    "xgb_model1 = None\n",
    "model_path = \"/kaggle/input/als-e-106-pp0-40-xgb-5fold/result1.pkl\"\n",
    "with open( model_path, \"rb\") as fp:\n",
    "    result = pickle.load(fp)\n",
    "    xgb_model1 = result[\"model\"]\n",
    "    xgb_model1.set_params(\n",
    "        early_stopping_rounds=50,\n",
    "        gamma=0.4,\n",
    "        tree_method=\"hist\",\n",
    "        max_depth=5,\n",
    "        eval_metric='rmse',\n",
    "        learning_rate=0.05\n",
    "    )\n",
    "\n",
    "xgb_model2 = None\n",
    "model_path = \"/kaggle/input/als-e-106-pp0-40-xgb-5fold/result2.pkl\"\n",
    "with open( model_path, \"rb\") as fp:\n",
    "    result = pickle.load(fp)\n",
    "    xgb_model2 = result[\"model\"]\n",
    "    xgb_model2.set_params(\n",
    "        early_stopping_rounds=50,\n",
    "        gamma=0.4,\n",
    "        tree_method=\"hist\",\n",
    "        max_depth=5,\n",
    "        eval_metric='rmse',\n",
    "        learning_rate=0.05\n",
    "    )\n",
    "    \n",
    "xgb_model3 = None\n",
    "model_path = \"/kaggle/input/als-e-106-pp0-40-xgb-5fold/result3.pkl\"\n",
    "with open( model_path, \"rb\") as fp:\n",
    "    result = pickle.load(fp)\n",
    "    xgb_model3 = result[\"model\"]\n",
    "    xgb_model3.set_params(\n",
    "        early_stopping_rounds=50,\n",
    "        gamma=0.4,\n",
    "        tree_method=\"hist\",\n",
    "        max_depth=5,\n",
    "        eval_metric='rmse',\n",
    "        learning_rate=0.05\n",
    "    )\n",
    "    \n",
    "xgb_model4 = None\n",
    "model_path = \"/kaggle/input/als-e-106-pp0-40-xgb-5fold/result4.pkl\"\n",
    "with open( model_path, \"rb\") as fp:\n",
    "    result = pickle.load(fp)\n",
    "    xgb_model4 = result[\"model\"]\n",
    "    xgb_model4.set_params(\n",
    "        early_stopping_rounds=50,\n",
    "        gamma=0.4,\n",
    "        tree_method=\"hist\",\n",
    "        max_depth=5,\n",
    "        eval_metric='rmse',\n",
    "        learning_rate=0.05\n",
    "    )\n",
    "    \n",
    "xgb_model5 = None\n",
    "model_path = \"/kaggle/input/js-with-lags-trained-xgb/result.pkl\"\n",
    "with open( model_path, \"rb\") as fp:\n",
    "    result = pickle.load(fp)\n",
    "    xgb_model5 = result[\"model\"]\n",
    "    xgb_model5.set_params(\n",
    "        early_stopping_rounds=50,\n",
    "        gamma=0.4,\n",
    "        tree_method=\"hist\",\n",
    "        max_depth=5,\n",
    "        eval_metric='rmse',\n",
    "        learning_rate=0.05\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "deea1a35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:21.288862Z",
     "iopub.status.busy": "2025-01-13T06:33:21.288628Z",
     "iopub.status.idle": "2025-01-13T06:33:21.298995Z",
     "shell.execute_reply": "2025-01-13T06:33:21.298285Z"
    },
    "papermill": {
     "duration": 0.020951,
     "end_time": "2025-01-13T06:33:21.300115",
     "exception": false,
     "start_time": "2025-01-13T06:33:21.279164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=&#x27;cuda&#x27;, early_stopping_rounds=50,\n",
       "             enable_categorical=False, eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
       "             gamma=0.4, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=200, n_gpus=2, n_jobs=None,\n",
       "             num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=&#x27;cuda&#x27;, early_stopping_rounds=50,\n",
       "             enable_categorical=False, eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
       "             gamma=0.4, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=200, n_gpus=2, n_jobs=None,\n",
       "             num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device='cuda', early_stopping_rounds=50,\n",
       "             enable_categorical=False, eval_metric='rmse', feature_types=None,\n",
       "             gamma=0.4, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=200, n_gpus=2, n_jobs=None,\n",
       "             num_parallel_tree=None, ...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show model\n",
    "display(xgb_model5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db8ee96a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:21.318615Z",
     "iopub.status.busy": "2025-01-13T06:33:21.318403Z",
     "iopub.status.idle": "2025-01-13T06:33:21.321860Z",
     "shell.execute_reply": "2025-01-13T06:33:21.321282Z"
    },
    "papermill": {
     "duration": 0.0139,
     "end_time": "2025-01-13T06:33:21.323010",
     "exception": false,
     "start_time": "2025-01-13T06:33:21.309110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GaussianNoise(nn.Module):\n",
    "    def __init__(self, std=0.1):\n",
    "        super().__init__()\n",
    "        self.std = std\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:  # Only add noise during training\n",
    "            noise = torch.randn_like(x) * self.std\n",
    "            return x + noise\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08f92ec4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:21.341431Z",
     "iopub.status.busy": "2025-01-13T06:33:21.341213Z",
     "iopub.status.idle": "2025-01-13T06:33:21.346058Z",
     "shell.execute_reply": "2025-01-13T06:33:21.345452Z"
    },
    "papermill": {
     "duration": 0.01547,
     "end_time": "2025-01-13T06:33:21.347332",
     "exception": false,
     "start_time": "2025-01-13T06:33:21.331862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, output_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.noise = GaussianNoise(std = .1)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.noise(x)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "189600ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:21.365719Z",
     "iopub.status.busy": "2025-01-13T06:33:21.365517Z",
     "iopub.status.idle": "2025-01-13T06:33:21.498383Z",
     "shell.execute_reply": "2025-01-13T06:33:21.497505Z"
    },
    "papermill": {
     "duration": 0.143694,
     "end_time": "2025-01-13T06:33:21.499862",
     "exception": false,
     "start_time": "2025-01-13T06:33:21.356168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstm_model = LSTM(input_size=79, hidden_dim=512, output_size = 1, num_layers = 1).to(device)\n",
    "lstm_model.load_state_dict(torch.load('/kaggle/input/jsmodel-chan-lstm/torchlstm.pth', map_location=device,weights_only= True))\n",
    "lstm_model.eval()\n",
    "sel_cols  = [f\"feature_{i:02d}\" for i in range(79)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ee57c38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:21.519006Z",
     "iopub.status.busy": "2025-01-13T06:33:21.518789Z",
     "iopub.status.idle": "2025-01-13T06:33:21.531445Z",
     "shell.execute_reply": "2025-01-13T06:33:21.530752Z"
    },
    "papermill": {
     "duration": 0.023206,
     "end_time": "2025-01-13T06:33:21.532592",
     "exception": false,
     "start_time": "2025-01-13T06:33:21.509386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "means_ = {'feature_00': 0.640198826789856, 'feature_01': 0.03755598142743111, 'feature_02': 0.6368075609207153, 'feature_03': 0.6365063786506653, 'feature_04': 0.013741530478000641, 'feature_05': -0.02173694409430027, 'feature_06': -0.006415014620870352, 'feature_07': -0.010971736162900925, 'feature_08': -0.04653771221637726, 'feature_09': 32.596106194690265, 'feature_10': 4.95929203539823, 'feature_11': 167.6541592920354, 'feature_12': -0.13415881991386414, 'feature_13': -0.07573335617780685, 'feature_14': -0.12015637010335922, 'feature_15': -0.7470195889472961, 'feature_16': -0.6257441639900208, 'feature_17': -0.7294047474861145, 'feature_18': -0.042215555906295776, 'feature_19': -0.08798160403966904, 'feature_20': -0.15741558372974396, 'feature_21': 0.10528526455163956, 'feature_22': 0.018054703250527382, 'feature_23': 0.03165541961789131, 'feature_24': 2.733017921447754, 'feature_25': 0.39958420395851135, 'feature_26': -0.11045943945646286, 'feature_27': -0.5332594513893127, 'feature_28': -0.4522790312767029, 'feature_29': -0.5739678144454956, 'feature_30': -0.7905704975128174, 'feature_31': 0.10600688308477402, 'feature_32': 0.40044134855270386, 'feature_33': -0.021725023165345192, 'feature_34': 0.4226262867450714, 'feature_35': 0.42143046855926514, 'feature_36': -0.00023802756913937628, 'feature_37': 0.027961043640971184, 'feature_38': 0.010258913040161133, 'feature_39': 0.005768273025751114, 'feature_40': 0.017485467717051506, 'feature_41': 0.038347117602825165, 'feature_42': -0.06123563274741173, 'feature_43': -0.11644423753023148, 'feature_44': -0.12342483550310135, 'feature_45': -0.028769943863153458, 'feature_46': -0.015200662426650524, 'feature_47': 0.015717582777142525, 'feature_48': -0.0033910537604242563, 'feature_49': -0.0052393232472240925, 'feature_50': -0.2285808026790619, 'feature_51': -0.3548349440097809, 'feature_52': -0.358092725276947, 'feature_53': 0.2607136368751526, 'feature_54': 0.18796788156032562, 'feature_55': 0.3154229521751404, 'feature_56': -0.1471923440694809, 'feature_57': 0.15730056166648865, 'feature_58': -0.021774644032120705, 'feature_59': -0.0037768862675875425, 'feature_60': -0.010220836848020554, 'feature_61': -0.03178725391626358, 'feature_62': -0.3769100308418274, 'feature_63': -0.3229374587535858, 'feature_64': -0.3718394339084625, 'feature_65': -0.10233989357948303, 'feature_66': -0.13688170909881592, 'feature_67': -0.14402112364768982, 'feature_68': -0.06875362992286682, 'feature_69': -0.11862917989492416, 'feature_70': -0.11789549142122269, 'feature_71': -0.06013699993491173, 'feature_72': -0.10766122490167618, 'feature_73': -0.09921672940254211, 'feature_74': -0.10233042389154434, 'feature_75': -0.05991339311003685, 'feature_76': -0.06349952518939972, 'feature_77': -0.07424316555261612, 'feature_78': -0.07759837061166763}\n",
    "stds_ = {'feature_00': 1.027751088142395, 'feature_01': 1.0967519283294678, 'feature_02': 1.0156300067901611, 'feature_03': 1.0170334577560425, 'feature_04': 1.0726385116577148, 'feature_05': 0.9639211297035217, 'feature_06': 1.0963259935379028, 'feature_07': 1.0789952278137207, 'feature_08': 0.7962697148323059, 'feature_09': 23.72976726545254, 'feature_10': 3.1867162933797224, 'feature_11': 163.44513161352285, 'feature_12': 0.6700984835624695, 'feature_13': 0.5805172920227051, 'feature_14': 0.664044201374054, 'feature_15': 0.37517768144607544, 'feature_16': 0.3393096327781677, 'feature_17': 0.3603287935256958, 'feature_18': 0.9911752939224243, 'feature_19': 1.0550744533538818, 'feature_20': 0.6643751263618469, 'feature_21': 0.38239365816116333, 'feature_22': 0.950261116027832, 'feature_23': 0.8119344711303711, 'feature_24': 1.4362775087356567, 'feature_25': 1.0947270393371582, 'feature_26': 1.077124834060669, 'feature_27': 1.0645726919174194, 'feature_28': 1.0676648616790771, 'feature_29': 0.2640742361545563, 'feature_30': 0.19689509272575378, 'feature_31': 0.3815343976020813, 'feature_32': 1.2996565103530884, 'feature_33': 0.9989405870437622, 'feature_34': 1.3409572839736938, 'feature_35': 1.3365675210952759, 'feature_36': 0.8695492148399353, 'feature_37': 0.7334080934524536, 'feature_38': 0.698810338973999, 'feature_39': 0.7965824604034424, 'feature_40': 0.518515944480896, 'feature_41': 0.6384949088096619, 'feature_42': 0.8168442249298096, 'feature_43': 0.5228385925292969, 'feature_44': 0.6521403193473816, 'feature_45': 0.8666537404060364, 'feature_46': 0.9039222002029419, 'feature_47': 3.2711963653564453, 'feature_48': 0.6570901274681091, 'feature_49': 0.7083076238632202, 'feature_50': 1.0132617950439453, 'feature_51': 0.6081287860870361, 'feature_52': 0.9250587224960327, 'feature_53': 1.0421689748764038, 'feature_54': 0.5859629511833191, 'feature_55': 0.9191848039627075, 'feature_56': 0.9549097418785095, 'feature_57': 1.0204777717590332, 'feature_58': 0.8327276110649109, 'feature_59': 0.8309783339500427, 'feature_60': 0.8389413356781006, 'feature_61': 1.192766547203064, 'feature_62': 1.388945460319519, 'feature_63': 0.09957146644592285, 'feature_64': 0.3396177291870117, 'feature_65': 1.01683509349823, 'feature_66': 1.0824761390686035, 'feature_67': 0.642227828502655, 'feature_68': 0.5312599539756775, 'feature_69': 0.6208390593528748, 'feature_70': 0.6724499464035034, 'feature_71': 0.5356909036636353, 'feature_72': 0.6534596681594849, 'feature_73': 1.0855497121810913, 'feature_74': 1.0880277156829834, 'feature_75': 1.2321789264678955, 'feature_76': 1.2345560789108276, 'feature_77': 1.0921478271484375, 'feature_78': 1.0924347639083862}\n",
    "def normalize_dataframe(df: pl.DataFrame, means: dict, stds: dict) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Normalize a Polars DataFrame using the provided means and standard deviations.\n",
    "\n",
    "    Args:\n",
    "    df (pl.DataFrame): The input DataFrame to normalize\n",
    "    means (dict): A dictionary of column means\n",
    "    stds (dict): A dictionary of column standard deviations\n",
    "\n",
    "    Returns:\n",
    "    pl.DataFrame: The normalized DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a list to store our normalization expressions\n",
    "    normalize_exprs = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col in means and col in stds:\n",
    "            # Ensure we don't divide by zero\n",
    "            if stds[col] != 0:\n",
    "                normalize_exprs.append(\n",
    "                    ((pl.col(col) - means[col]) / stds[col]).alias(col)\n",
    "                )\n",
    "            else:\n",
    "                # If std is 0, just subtract the mean\n",
    "                normalize_exprs.append(\n",
    "                    (pl.col(col) - means[col]).alias(col)\n",
    "                )\n",
    "        else:\n",
    "            # If we don't have mean/std for this column, leave it as is\n",
    "            normalize_exprs.append(pl.col(col))\n",
    "\n",
    "    # Apply the normalization to the dataframe\n",
    "    normalized_df = df.select(normalize_exprs)\n",
    "\n",
    "    return normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10d1dbce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:21.551013Z",
     "iopub.status.busy": "2025-01-13T06:33:21.550806Z",
     "iopub.status.idle": "2025-01-13T06:33:21.578046Z",
     "shell.execute_reply": "2025-01-13T06:33:21.577448Z"
    },
    "papermill": {
     "duration": 0.037906,
     "end_time": "2025-01-13T06:33:21.579279",
     "exception": false,
     "start_time": "2025-01-13T06:33:21.541373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgbm_original = lgb.Booster(model_file=CONFIG.data_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3c27dfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:21.597759Z",
     "iopub.status.busy": "2025-01-13T06:33:21.597550Z",
     "iopub.status.idle": "2025-01-13T06:33:21.600968Z",
     "shell.execute_reply": "2025-01-13T06:33:21.600373Z"
    },
    "papermill": {
     "duration": 0.01393,
     "end_time": "2025-01-13T06:33:21.602034",
     "exception": false,
     "start_time": "2025-01-13T06:33:21.588104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Params used to retrain\n",
    "input_params = {\"num_leaves\": 31, \"feature_fraction\": 0.9, \"n_estimators\": 100, \"learning_rate\": 0.1}\n",
    "\n",
    "# Define Parameters\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',                                      # Root Mean Squared Error\n",
    "    'boosting_type': 'gbdt',                               # Gradient Boosted Decision Trees\n",
    "    'num_leaves': input_params['num_leaves'],\n",
    "    'learning_rate': input_params['learning_rate'],\n",
    "    'feature_fraction': input_params['feature_fraction'],\n",
    "    'n_estimators': input_params['n_estimators']      \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "330d57ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:21.620700Z",
     "iopub.status.busy": "2025-01-13T06:33:21.620496Z",
     "iopub.status.idle": "2025-01-13T06:33:21.644749Z",
     "shell.execute_reply": "2025-01-13T06:33:21.644196Z"
    },
    "papermill": {
     "duration": 0.034939,
     "end_time": "2025-01-13T06:33:21.645817",
     "exception": false,
     "start_time": "2025-01-13T06:33:21.610878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lags_ : pl.DataFrame | None = None\n",
    "\n",
    "lags_history = None\n",
    "\n",
    "# lgb online retrain global variables start\n",
    "\n",
    "# Initialize global vars\n",
    "cache = None\n",
    "cache_list = []\n",
    "# tot nb of days counter\n",
    "day_count = 0\n",
    "# training counter to be reset after each train\n",
    "train_counter = 0\n",
    "lgbm_retrained = None\n",
    "\n",
    "labels : pl.DataFrame | None = None\n",
    "# Each batch of predictions (except the very first) must be returned within 1 minute of the batch features being provided.\n",
    "\n",
    "# end\n",
    "\n",
    "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    \"\"\"Make a prediction.\"\"\"\n",
    "    \n",
    "    global cache          # Declare the global cache\n",
    "    global day_count\n",
    "    global lgbm_retrained\n",
    "    global lags_\n",
    "    global history\n",
    "    global lags_infer\n",
    "    global lags_history\n",
    "    global cache_list\n",
    "    global labels\n",
    "    global train_counter\n",
    "    # global gt\n",
    "\n",
    "    if lags is not None:\n",
    "        lags_ = lags\n",
    "\n",
    "        # lgb online retrain global variable update start\n",
    "        day_count += 1\n",
    "        train_counter += 1\n",
    "        # store ground truth from previous day\n",
    "        update_labels = lags_[\"date_id\", \"symbol_id\", \"time_id\",\"responder_6_lag_1\"]\n",
    "        lag_cols_rename = {\"responder_6_lag_1\": \"responder_6\"}\n",
    "        update_labels = update_labels.rename(lag_cols_rename)\n",
    "        if labels is not None:\n",
    "            labels = pl.concat([labels, update_labels], rechunk=True)\n",
    "        else:\n",
    "            labels = update_labels\n",
    "        # end\n",
    "    \n",
    "    # lstm start\n",
    "    test_lstm = test.clone()\n",
    "    missing_cols = set(sel_cols) - set(test_lstm.columns)\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing columns in test data: {missing_cols}\")\n",
    "        \n",
    "    # Select the features\n",
    "    test_features_lstm = test_lstm.select(sel_cols)\n",
    "    # **Apply forward fill and then fill remaining missing values with zero**\n",
    "    test_features_lstm = test_features_lstm.fill_null(strategy='forward').fill_null(0)\n",
    "    test_features_lstm = normalize_dataframe(test_features_lstm, means_,stds_)\n",
    "    # Convert Polars DataFrame to NumPy array\n",
    "    X_test_lstm = test_features_lstm.to_numpy()\n",
    "    # Convert to Torch tensor\n",
    "    X_test_tensor_lstm = torch.tensor(X_test_lstm, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Make predictions\n",
    "    with torch.no_grad():        \n",
    "        outputs_lstm = lstm_model(X_test_tensor_lstm)\n",
    "        # Assuming the model outputs a tensor of shape (batch_size, 1)\n",
    "        pred_lstm = outputs_lstm.squeeze().cpu().numpy()\n",
    "    \n",
    "    # lstm end\n",
    "\n",
    "    # quadra xgb start\n",
    "    # lagsxgb = lags_.clone().group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last()\n",
    "    # testxgb = test.clone().join(lagsxgb, on=[\"date_id\", \"symbol_id\"], how=\"left\")\n",
    "\n",
    "    # preds_qxgb = np.zeros((testxgb.shape[0],))\n",
    "    # preds_qxgb += xgb_model.predict(testxgb[xgb_feature_cols].to_pandas()) * 0.25\n",
    "    # preds_qxgb += xgb_model2.predict(testxgb[xgb_feature_cols].to_pandas()) * 0.25\n",
    "    # preds_qxgb += xgb_model4.predict(testxgb[xgb_feature_cols].to_pandas()) * 0.25\n",
    "    # preds_qxgb += xgb_model5.predict(testxgb[xgb_feature_cols].to_pandas()) * 0.25\n",
    "    # quadra xgb end\n",
    "    \n",
    "    test_tab = test.clone()\n",
    "    for col in feature_cat + ['symbol_id', 'time_id']:\n",
    "        test_tab = encode_column(test_tab, col, category_mappings[col])\n",
    "        \n",
    "    # Initialize predictions with `row_id`\n",
    "    predictions = test.select('row_id').with_columns(\n",
    "        pl.lit(0.0).alias('responder_6')\n",
    "    )\n",
    "\n",
    "    # lgb online retrain code\n",
    "    test_lgb_re = test.clone()\n",
    "    lags__lgb_re = lags_.clone()\n",
    "    if not lags__lgb_re is None:\n",
    "        lags_lgb_re = lags__lgb_re.group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last() # pick up last record of previous date\n",
    "        lags_lgb_re = lags_lgb_re.drop([\"time_id\"])\n",
    "        test_lgb_re = test_lgb_re.join(lags_lgb_re, on=[\"date_id\", \"symbol_id\"],  how=\"left\")\n",
    "    else:\n",
    "        test_lgb_re = test_lgb_re.with_columns(\n",
    "            ( pl.lit(0.0).alias(f'responder_{idx}_lag_1') for idx in range(9) )\n",
    "        )\n",
    "    if CONFIG.retrain:\n",
    "        # store data for each batch\n",
    "        cache_list.append(test_lgb_re)\n",
    "        \n",
    "    # initialize preds\n",
    "    preds_lgb_re = np.zeros((test_lgb_re.shape[0],))\n",
    "    \n",
    "    # lightgbm model\n",
    "    X_lgb_re = test_lgb_re[CONFIG.feature_colss].to_numpy()\n",
    "\n",
    "    # re-train a model on the fly every N days\n",
    "    if CONFIG.retrain and train_counter % 4 == 0 and day_count>=60:\n",
    "        # print(\"Start retraining\")\n",
    "        if cache is not None:\n",
    "            cache_update = pl.concat(cache_list, rechunk=True)\n",
    "            cache = pl.concat([cache, cache_update], rechunk=True)\n",
    "        else:\n",
    "            cache = pl.concat(cache_list, rechunk=True)\n",
    "        # filter labels\n",
    "        # move data back to the previous day (we receive the lags at the same day but they are the ground truth of the previous day)\n",
    "        df = labels.with_columns(\n",
    "            (pl.col(\"date_id\") -1).alias(\"date_id\")\n",
    "        )\n",
    "        df = df.filter(pl.col(\"date_id\") >= np.min(cache[\"date_id\"].to_numpy()))\n",
    "        # prepare data for training\n",
    "        train = cache.join(df, on=[\"date_id\", \"symbol_id\", \"time_id\"],  how=\"left\")\n",
    "        \n",
    "        # drop columns where labels are none (normally last day)\n",
    "        train_cleaned = train.filter(pl.col(CONFIG.target_col).is_not_nan())\n",
    "        \n",
    "        X_train = train_cleaned[CONFIG.feature_colss].to_numpy()\n",
    "        y_train = train_cleaned[CONFIG.target_col].to_numpy().flatten()\n",
    "\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        \n",
    "        # Re-train the model\n",
    "        lgbm_retrained = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            num_boost_round=40\n",
    "        )\n",
    "        # reset counter otherwise we will retrain for each time_id of the same day\n",
    "        train_counter = 1\n",
    "        # empty cache list\n",
    "        cache_list = []\n",
    "\n",
    "        # store only last 50 days\n",
    "        days = np.unique(cache[\"date_id\"].to_numpy())\n",
    "        days = days[-40:]\n",
    "        min_day = np.min(days)\n",
    "        cache = cache.filter(pl.col(\"date_id\") >= min_day)\n",
    "        \n",
    "    # average original model with new retrained model\n",
    "    if lgbm_retrained:\n",
    "        # lightgbm models\n",
    "        pred_lgbm_retrained = lgbm_retrained.predict(X_lgb_re, num_iteration=lgbm_original.best_iteration)\n",
    "        pred_lgbm_original = lgbm_original.predict(X_lgb_re, num_iteration=lgbm_original.best_iteration)\n",
    "        # simple average\n",
    "        # weight more the prediction from the new model retrained on the new data\n",
    "        pred_online_retrain = (0.6 * pred_lgbm_retrained + 0.4 * pred_lgbm_original)\n",
    "    else:\n",
    "        # lightgbm model\n",
    "        pred_online_retrain = lgbm_original.predict(X_lgb_re, num_iteration=lgbm_original.best_iteration)\n",
    "\n",
    "    # end\n",
    "\n",
    "    # Prepare test_nn for NN processing\n",
    "    test_nn = test.clone()\n",
    "    symbol_ids = test_nn.select('symbol_id').to_numpy()[:, 0]\n",
    "    current_date = test.select(\"date_id\").to_numpy()[:, 0][0]\n",
    "    time_id = test.select(\"time_id\").to_numpy()[0]\n",
    "    timie_id_array = test.select(\"time_id\").to_numpy()[:, 0]\n",
    "\n",
    "    # for tabm\n",
    "    if time_id == 0:\n",
    "        lagsss = lags.with_columns(pl.col('time_id').cast(pl.Int64))\n",
    "        lagsss = lagsss.with_columns(pl.col('symbol_id').cast(pl.Int64))\n",
    "    \n",
    "        lags_history = lagsss\n",
    "        lagsss = lagsss.filter(pl.col(\"time_id\") == 0)\n",
    "        \n",
    "        \n",
    "        test_tab = test_tab.join(lagsss, on=[\"time_id\", \"symbol_id\"],  how=\"left\")\n",
    "    else:\n",
    "        lagsss = lags_history.filter(pl.col(\"time_id\") == time_id)\n",
    "        test_tab = test_tab.join(lagsss, on=[\"time_id\", \"symbol_id\"],  how=\"left\")\n",
    "        \n",
    "    test_tab = test_tab.with_columns([\n",
    "        pl.col(col).fill_null(0) for col in feature_list + [f\"responder_{idx}_lag_1\" for idx in range(9)] \n",
    "    ])\n",
    "\n",
    "    test_tab = standardize(test_tab, std_feature, means, stds)\n",
    "\n",
    "\n",
    "    X_test_ = test_tab[feature_test].to_numpy()\n",
    "    X_test_tensor = torch.tensor(X_test_, dtype=torch.float32).to(device)\n",
    "\n",
    "    symbol_tensor = torch.tensor(symbol_ids, dtype=torch.float32).to(device)\n",
    "    time_tensor = torch.tensor(timie_id_array, dtype=torch.float32).to(device)\n",
    "    X_cat = X_test_tensor[:, [9, 10, 11]]\n",
    "    X_cont = X_test_tensor[:, [i for i in range(X_test_tensor.shape[1]) if i not in [9, 10, 11]]]\n",
    "    # X_cont = X_cont + torch.randn_like(X_cont) * 0.02\n",
    "\n",
    "    X_cat = (torch.concat([X_cat, symbol_tensor.unsqueeze(-1), time_tensor.unsqueeze(-1)], axis=1)).to(torch.int64)\n",
    "    \n",
    "\n",
    "    tab_model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        outputs = tab_model(X_cont, X_cat)\n",
    "        # Assuming the model outputs a tensor of shape (batch_size, 1)\n",
    "        preds_tab = outputs.squeeze(-1).cpu().numpy()\n",
    "        preds_tab = preds_tab.mean(1)\n",
    "    # end\n",
    "\n",
    "    # rdg start\n",
    "    lagsrdg = lags_.clone().group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last() # pick up \n",
    "    testrdg = test.clone().join(lagsrdg, on=[\"date_id\", \"symbol_id\"],  how=\"left\")\n",
    "    predsrdg = np.zeros((testrdg.shape[0],))\n",
    "\n",
    "    predsrdg = predict_ridge(testrdg,lagsrdg)\n",
    "    # rdg end\n",
    "    \n",
    "    if lags is not None:\n",
    "        lagss = lags.rename(CONFIG.lag_cols_rename)\n",
    "        lagss = lagss.cast(history_column_types)\n",
    "        lagss = lagss.cast(responder_column_types)\n",
    "\n",
    "        history = pl.concat([history, lagss])\n",
    "        \n",
    "        # 只储存最近N天的历史数据\n",
    "        history = history.filter(pl.col(\"date_id\") > (current_date - CONFIG.lag_ndays))\n",
    "\n",
    "        # 这里用的XGB模型只使用了shift 1天的统计值\n",
    "        agg_list = create_agg_list(1, CONFIG.lag_target_cols_name)\n",
    "        shift_n_data = history.filter(pl.col(\"date_id\") == current_date)\n",
    "        lags_infer = shift_n_data.group_by([\"date_id\", \"symbol_id\"], maintain_order=True).agg(agg_list)\n",
    "\n",
    "    test_ = test.cast(history_column_types)\n",
    "    test_ = test_.cast(feature_column_types)\n",
    "    # 在一个date_id下的所有batch用到的lags_infer是相同的\n",
    "    # 像lags_infer这样的统计特征在每个date_id的time_id=0时构造完成\n",
    "    X_test = test_.join(lags_infer, on=[\"date_id\", \"symbol_id\"], how=\"left\")\n",
    "    \n",
    "    preds_xgb = np.zeros((X_test.shape[0],))\n",
    "    preds_xgb += model.predict(X_test[features].to_pandas().values)\n",
    "    \n",
    "    if lags is not None:\n",
    "        lags = lags.group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last()\n",
    "        test_nn = test_nn.join(lags, on=[\"date_id\", \"symbol_id\"], how=\"left\")\n",
    "    else:\n",
    "        test_nn = test_nn.with_columns(\n",
    "            (pl.lit(0.0).alias(f'responder_{idx}_lag_1') for idx in range(9))\n",
    "        )\n",
    "\n",
    "    # CatBoost predictions\n",
    "    feat_cat = test[FEAT_COLS_CAT + ['symbol_id', 'weight', 'time_id']].to_pandas()\n",
    "    feat_cat = feat_cat.fillna('NaN').astype(str)\n",
    "    # pred_cat = [model.predict(feat_cat) for model in catboost_models]\n",
    "    # pred_cat = np.mean(pred_cat, axis=0)\n",
    "    \n",
    "    pred_cat2 = catboost_holdout_model.predict(feat_cat)\n",
    "\n",
    "\n",
    "    # LightGBM predictions\n",
    "    feat_lgb = test_nn[FEAT_COLS_LGB + ['weight', 'symbol_id', 'time_id']].to_pandas()\n",
    "    # feat_lgb['pred_cat'] = pred_cat\n",
    "    pred_lgb = [model.predict(feat_lgb) for model in lgb_models]\n",
    "    pred_lgb = np.mean(pred_lgb, axis=0)\n",
    "    \n",
    "    # Neural network predictions\n",
    "    preds_nn = np.zeros((test_nn.shape[0],))\n",
    "    test_input = test_nn[CONFIG.feature_cols].to_pandas()\n",
    "    test_input = test_input.fillna(method='ffill').fillna(0)\n",
    "    test_input = torch.FloatTensor(test_input.values).to(\"cuda:0\")\n",
    "    with torch.no_grad():\n",
    "        for i, nn_model in enumerate(tqdm(nn_models)):\n",
    "            nn_model.eval()\n",
    "            preds_nn += nn_model(test_input).cpu().numpy() / len(nn_models)\n",
    "    print(f\"predict> nn_preds.shape =\", preds_nn.shape)\n",
    "\n",
    "    # Final prediction\n",
    "    pred = pred_lgb * 0.1 + preds_nn * 0.3 + preds_tab * 0.2 + pred_cat2 * 0.15 + preds_xgb * 0.2 + predsrdg * 0.1  + pred_lstm * 0.05 + pred_online_retrain * 0.1\n",
    "\n",
    "    # Clip predictions to the range [-5, 5]\n",
    "    predictions = test.select('row_id').with_columns(\n",
    "        pl.Series(\n",
    "            name='responder_6',\n",
    "            values=np.clip(pred, a_min=-5, a_max=5),\n",
    "            dtype=pl.Float64\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(predictions)\n",
    "    \n",
    "    assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n",
    "    assert list(predictions.columns) == ['row_id', 'responder_6']\n",
    "    assert len(predictions) == len(test)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6225fd45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:21.664356Z",
     "iopub.status.busy": "2025-01-13T06:33:21.664119Z",
     "iopub.status.idle": "2025-01-13T06:33:22.282251Z",
     "shell.execute_reply": "2025-01-13T06:33:22.281291Z"
    },
    "papermill": {
     "duration": 0.62926,
     "end_time": "2025-01-13T06:33:22.283984",
     "exception": false,
     "start_time": "2025-01-13T06:33:21.654724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb84166cc7b46b79b63441530b30351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict> nn_preds.shape = (39,)\n",
      "shape: (39, 2)\n",
      "┌────────┬─────────────┐\n",
      "│ row_id ┆ responder_6 │\n",
      "│ ---    ┆ ---         │\n",
      "│ i64    ┆ f64         │\n",
      "╞════════╪═════════════╡\n",
      "│ 0      ┆ 0.029505    │\n",
      "│ 1      ┆ 0.048384    │\n",
      "│ 2      ┆ -0.029644   │\n",
      "│ 3      ┆ -0.007676   │\n",
      "│ 4      ┆ 0.026923    │\n",
      "│ 5      ┆ 0.044062    │\n",
      "│ 6      ┆ 0.017532    │\n",
      "│ 7      ┆ 0.059194    │\n",
      "│ 8      ┆ 0.071777    │\n",
      "│ 9      ┆ 0.025686    │\n",
      "│ 10     ┆ 0.016923    │\n",
      "│ 11     ┆ 0.065242    │\n",
      "│ 12     ┆ -0.032249   │\n",
      "│ 13     ┆ 0.031587    │\n",
      "│ 14     ┆ 0.052508    │\n",
      "│ 15     ┆ -0.01222    │\n",
      "│ 16     ┆ 0.030412    │\n",
      "│ 17     ┆ -0.02157    │\n",
      "│ 18     ┆ -0.016674   │\n",
      "│ 19     ┆ 0.013744    │\n",
      "│ 20     ┆ -0.000098   │\n",
      "│ 21     ┆ 0.053155    │\n",
      "│ 22     ┆ 0.018272    │\n",
      "│ 23     ┆ 0.030464    │\n",
      "│ 24     ┆ -0.00867    │\n",
      "│ 25     ┆ -0.167841   │\n",
      "│ 26     ┆ -0.044406   │\n",
      "│ 27     ┆ 0.038685    │\n",
      "│ 28     ┆ -0.029133   │\n",
      "│ 29     ┆ -0.138711   │\n",
      "│ 30     ┆ 0.033299    │\n",
      "│ 31     ┆ -0.044333   │\n",
      "│ 32     ┆ 0.059728    │\n",
      "│ 33     ┆ 0.025443    │\n",
      "│ 34     ┆ 0.076561    │\n",
      "│ 35     ┆ -0.088737   │\n",
      "│ 36     ┆ 0.044877    │\n",
      "│ 37     ┆ 0.054521    │\n",
      "│ 38     ┆ 0.045612    │\n",
      "└────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (\n",
    "            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n",
    "            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f652d413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:22.304716Z",
     "iopub.status.busy": "2025-01-13T06:33:22.304479Z",
     "iopub.status.idle": "2025-01-13T06:33:22.307533Z",
     "shell.execute_reply": "2025-01-13T06:33:22.306833Z"
    },
    "papermill": {
     "duration": 0.014312,
     "end_time": "2025-01-13T06:33:22.308641",
     "exception": false,
     "start_time": "2025-01-13T06:33:22.294329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a95d62",
   "metadata": {
    "papermill": {
     "duration": 0.008911,
     "end_time": "2025-01-13T06:33:22.326592",
     "exception": false,
     "start_time": "2025-01-13T06:33:22.317681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. make valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "077122a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:22.345327Z",
     "iopub.status.busy": "2025-01-13T06:33:22.345077Z",
     "iopub.status.idle": "2025-01-13T06:33:22.348016Z",
     "shell.execute_reply": "2025-01-13T06:33:22.347371Z"
    },
    "papermill": {
     "duration": 0.013374,
     "end_time": "2025-01-13T06:33:22.349133",
     "exception": false,
     "start_time": "2025-01-13T06:33:22.335759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# valid_from = 1577 # for private you should change to 1455 (1 year)\n",
    "# alltraindata = pl.scan_parquet(\"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet\")\n",
    "# valid_df = alltraindata.filter(pl.col(\"date_id\")>=valid_from).collect()\n",
    "# valid_df = valid_df.with_columns(pl.Series(range(len(valid_df))).alias(\"row_id\"),\n",
    "#                                 pl.lit(True).alias(\"is_scored\"))\n",
    "# valid_df.write_parquet(\"valid_df.parquet\")\n",
    "# test_sample = pl.read_parquet(\"/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet/date_id=0/part-0.parquet\")\n",
    "# valid_df = valid_df.select(test_sample.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29962d05",
   "metadata": {
    "papermill": {
     "duration": 0.008831,
     "end_time": "2025-01-13T06:33:22.366911",
     "exception": false,
     "start_time": "2025-01-13T06:33:22.358080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. make lag function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88372254",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:22.385893Z",
     "iopub.status.busy": "2025-01-13T06:33:22.385695Z",
     "iopub.status.idle": "2025-01-13T06:33:22.388392Z",
     "shell.execute_reply": "2025-01-13T06:33:22.387793Z"
    },
    "papermill": {
     "duration": 0.013647,
     "end_time": "2025-01-13T06:33:22.389649",
     "exception": false,
     "start_time": "2025-01-13T06:33:22.376002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lag_sample = pl.read_parquet(\"/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet/date_id=0/part-0.parquet\")\n",
    "# train_sample = pl.read_parquet(\"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=0/part-0.parquet\",n_rows=1)\n",
    "# responder_cols = [s for s in train_sample.columns if \"responder\" in s]\n",
    "\n",
    "# def makelag(date_id):\n",
    "#     \"\"\"\n",
    "#     Making lag at the previout day\n",
    "\n",
    "#     Args:\n",
    "#     date_id (int): date_id at the previout day\n",
    "    \n",
    "#     Returns:\n",
    "#     pl.dataframe\n",
    "#     \"\"\"\n",
    "    \n",
    "#     lag = alltraindata.filter(pl.col(\"date_id\")==date_id).select([\"date_id\",\"time_id\",\"symbol_id\"] + responder_cols).collect()\n",
    "#     lag.columns = lag_sample.columns\n",
    "    \n",
    "#     return lag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad6288a",
   "metadata": {
    "papermill": {
     "duration": 0.013604,
     "end_time": "2025-01-13T06:33:22.414333",
     "exception": false,
     "start_time": "2025-01-13T06:33:22.400729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. make the test and lag data for debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6861c48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:22.432841Z",
     "iopub.status.busy": "2025-01-13T06:33:22.432631Z",
     "iopub.status.idle": "2025-01-13T06:33:22.435231Z",
     "shell.execute_reply": "2025-01-13T06:33:22.434630Z"
    },
    "papermill": {
     "duration": 0.013018,
     "end_time": "2025-01-13T06:33:22.436295",
     "exception": false,
     "start_time": "2025-01-13T06:33:22.423277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# os.makedirs(\"./debug/test.parquet\",exist_ok=True)\n",
    "# os.makedirs(\"./debug/lags.parquet\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34829511",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:22.454846Z",
     "iopub.status.busy": "2025-01-13T06:33:22.454637Z",
     "iopub.status.idle": "2025-01-13T06:33:22.457155Z",
     "shell.execute_reply": "2025-01-13T06:33:22.456596Z"
    },
    "papermill": {
     "duration": 0.01297,
     "end_time": "2025-01-13T06:33:22.458272",
     "exception": false,
     "start_time": "2025-01-13T06:33:22.445302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# total_iterations = len(valid_df[\"date_id\"].unique())\n",
    "# total_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0026b041",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:22.476821Z",
     "iopub.status.busy": "2025-01-13T06:33:22.476614Z",
     "iopub.status.idle": "2025-01-13T06:33:22.479176Z",
     "shell.execute_reply": "2025-01-13T06:33:22.478589Z"
    },
    "papermill": {
     "duration": 0.013235,
     "end_time": "2025-01-13T06:33:22.480413",
     "exception": false,
     "start_time": "2025-01-13T06:33:22.467178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for num_days, df_per_day in tqdm(valid_df.group_by(\"date_id\",maintain_order=True),total=total_iterations,desc=\"Processing\"):\n",
    "    \n",
    "       \n",
    "#     day = num_days[0] - valid_from # date_id must start from 0.\n",
    "    \n",
    "#     os.makedirs(f\"./debug/test.parquet/date_id={day}\",exist_ok=True)\n",
    "#     os.makedirs(f\"./debug/lags.parquet/date_id={day}\",exist_ok=True)\n",
    "    \n",
    "#     lag = makelag(num_days[0] - 1)\n",
    "    \n",
    "#     df_per_day.write_parquet(f\"./debug/test.parquet/date_id={day}/part-0.parquet\")\n",
    "#     lag.write_parquet(f\"./debug/lags.parquet/date_id={day}/part-0.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512bdfe3",
   "metadata": {
    "papermill": {
     "duration": 0.00863,
     "end_time": "2025-01-13T06:33:22.498151",
     "exception": false,
     "start_time": "2025-01-13T06:33:22.489521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. check submission using the evalution API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4258f52e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:22.516540Z",
     "iopub.status.busy": "2025-01-13T06:33:22.516331Z",
     "iopub.status.idle": "2025-01-13T06:33:22.518937Z",
     "shell.execute_reply": "2025-01-13T06:33:22.518373Z"
    },
    "papermill": {
     "duration": 0.01309,
     "end_time": "2025-01-13T06:33:22.520066",
     "exception": false,
     "start_time": "2025-01-13T06:33:22.506976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n",
    "\n",
    "# if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "#     inference_server.serve()\n",
    "# else:\n",
    "#     inference_server.run_local_gateway(\n",
    "#         (\n",
    "#             './debug/test.parquet',\n",
    "#             './debug/lags.parquet',\n",
    "#         )\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b0e2e09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:22.538749Z",
     "iopub.status.busy": "2025-01-13T06:33:22.538523Z",
     "iopub.status.idle": "2025-01-13T06:33:22.541133Z",
     "shell.execute_reply": "2025-01-13T06:33:22.540590Z"
    },
    "papermill": {
     "duration": 0.013038,
     "end_time": "2025-01-13T06:33:22.542330",
     "exception": false,
     "start_time": "2025-01-13T06:33:22.529292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_submission_dataframe = []\n",
    "# all_inference_times = []\n",
    "# timeout = 60\n",
    "# total_iterations = len(valid_df[\"date_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02792400",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:22.561178Z",
     "iopub.status.busy": "2025-01-13T06:33:22.560977Z",
     "iopub.status.idle": "2025-01-13T06:33:22.563816Z",
     "shell.execute_reply": "2025-01-13T06:33:22.563249Z"
    },
    "papermill": {
     "duration": 0.013784,
     "end_time": "2025-01-13T06:33:22.565028",
     "exception": false,
     "start_time": "2025-01-13T06:33:22.551244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## Step 1 The data is split by day using group_by.\n",
    "\n",
    "# for num_days, df_per_day in tqdm(valid_df.group_by(\"date_id\",maintain_order=True),total=total_iterations,desc=\"Processing\"):\n",
    "    \n",
    "#     ## Step 2 The data is split by time_id using group_by, and the lag is generated (for time_id == 0).\n",
    "    \n",
    "#     for time_id, test in df_per_day.group_by(\"time_id\",maintain_order=True):\n",
    "        \n",
    "#         ## when time_id == 0, makelags\n",
    "        \n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         if time_id[0] == 0:\n",
    "#             lag = makelag(num_days[0] - 1)\n",
    "#         else:\n",
    "#             lag = None\n",
    "        \n",
    "#         submission_dataframe = predict(test, lag)\n",
    "        \n",
    "#         all_submission_dataframe.append(submission_dataframe)\n",
    "        \n",
    "#         end_time = time.time()\n",
    "        \n",
    "#         diff = end_time - start_time\n",
    "        \n",
    "#         all_inference_times.append(diff)\n",
    "        \n",
    "#      #   print(f\"{num_days[0]=},{time_id[0]=}{diff=}\")\n",
    "        \n",
    "#         if diff > timeout:\n",
    "#             print(f\"{num_days[0]=},{time_id[0]=}{diff=}\")\n",
    "#             assert elapsed_time < timeout, f\"process over {timeout/60} mins. cancelled\"\n",
    "        \n",
    "# all_submission_dataframe = pl.concat(all_submission_dataframe)\n",
    "# all_submission_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e473f07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:22.583449Z",
     "iopub.status.busy": "2025-01-13T06:33:22.583235Z",
     "iopub.status.idle": "2025-01-13T06:33:22.585847Z",
     "shell.execute_reply": "2025-01-13T06:33:22.585276Z"
    },
    "papermill": {
     "duration": 0.013022,
     "end_time": "2025-01-13T06:33:22.586892",
     "exception": false,
     "start_time": "2025-01-13T06:33:22.573870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def weighted_zero_mean_r2(y_true, y_pred, weights):\n",
    "#     \"\"\"\n",
    "#     Calculate the sample weighted zero-mean R-squared score.\n",
    "\n",
    "#     Parameters:\n",
    "#     y_true (numpy.ndarray): Ground-truth values for responder_6.\n",
    "#     y_pred (numpy.ndarray): Predicted values for responder_6.\n",
    "#     weights (numpy.ndarray): Sample weight vector.\n",
    "\n",
    "#     Returns:\n",
    "#     float: The weighted zero-mean R-squared score.\n",
    "#     \"\"\"\n",
    "#     numerator = np.sum(weights * (y_true - y_pred)**2)\n",
    "#     denominator = np.sum(weights * y_true**2)\n",
    "    \n",
    "#     r2_score = 1 - numerator / denominator\n",
    "#     return r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d629d129",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:22.605684Z",
     "iopub.status.busy": "2025-01-13T06:33:22.605480Z",
     "iopub.status.idle": "2025-01-13T06:33:22.607975Z",
     "shell.execute_reply": "2025-01-13T06:33:22.607401Z"
    },
    "papermill": {
     "duration": 0.013235,
     "end_time": "2025-01-13T06:33:22.609066",
     "exception": false,
     "start_time": "2025-01-13T06:33:22.595831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# valid_df = pl.read_parquet(\"valid_df.parquet\")\n",
    "# y_true = valid_df.select(\"responder_6\").to_numpy().reshape(-1)\n",
    "# y_pred = all_submission_dataframe.select(\"responder_6\").to_numpy().reshape(-1)\n",
    "# weights = valid_df.select(\"weight\").to_numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3d590db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:33:22.627596Z",
     "iopub.status.busy": "2025-01-13T06:33:22.627390Z",
     "iopub.status.idle": "2025-01-13T06:33:22.629943Z",
     "shell.execute_reply": "2025-01-13T06:33:22.629381Z"
    },
    "papermill": {
     "duration": 0.013099,
     "end_time": "2025-01-13T06:33:22.631107",
     "exception": false,
     "start_time": "2025-01-13T06:33:22.618008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# weighted_zero_mean_r2(y_true, y_pred, weights)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9871156,
     "sourceId": 84493,
     "sourceType": "competition"
    },
    {
     "datasetId": 6006872,
     "sourceId": 9801075,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6010899,
     "sourceId": 9806342,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6035149,
     "sourceId": 9838282,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6293027,
     "sourceId": 10186479,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6297065,
     "sourceId": 10253875,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6378806,
     "sourceId": 10304887,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6410107,
     "sourceId": 10351700,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6433793,
     "sourceId": 10386263,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6434411,
     "sourceId": 10386352,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6467169,
     "sourceId": 10448107,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 211920287,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 214286693,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 215616115,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 216017958,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 46.690364,
   "end_time": "2025-01-13T06:33:25.386998",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-13T06:32:38.696634",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0f074ff1ff1043f990daeb409b5a414b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "12ee7036b5f1466dba93efb181b3c342": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4c59a52366404856b620e15175e78075": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6377d39d61d44e548247a6fdd9b91763": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9a9f76096dfd43a79c72b49d828bad33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f5d53c60d0784e91a2fc87b196470e62",
       "placeholder": "​",
       "style": "IPY_MODEL_d4395e24ea174274bd5f2fe8675a406e",
       "tabbable": null,
       "tooltip": null,
       "value": " 5/5 [00:00&lt;00:00, 53.86it/s]"
      }
     },
     "a825b02295734d0da2211835921cf9fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_12ee7036b5f1466dba93efb181b3c342",
       "placeholder": "​",
       "style": "IPY_MODEL_4c59a52366404856b620e15175e78075",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "d4395e24ea174274bd5f2fe8675a406e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d4a3fe6cd23547cf97067282d2aeea3d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6377d39d61d44e548247a6fdd9b91763",
       "max": 5.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0f074ff1ff1043f990daeb409b5a414b",
       "tabbable": null,
       "tooltip": null,
       "value": 5.0
      }
     },
     "f5d53c60d0784e91a2fc87b196470e62": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f9694e0d07e2462b8639146566f7df95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fbb84166cc7b46b79b63441530b30351": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a825b02295734d0da2211835921cf9fe",
        "IPY_MODEL_d4a3fe6cd23547cf97067282d2aeea3d",
        "IPY_MODEL_9a9f76096dfd43a79c72b49d828bad33"
       ],
       "layout": "IPY_MODEL_f9694e0d07e2462b8639146566f7df95",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
